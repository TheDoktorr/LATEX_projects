    \documentclass[11pt]{article}
    \usepackage{amsmath}
    \usepackage{graphicx}
    \usepackage{multirow}
    \usepackage{booktabs}
    \usepackage{subfigure}
    \usepackage{verbatim}
    \usepackage{color}
    \usepackage{hyperref}
    \usepackage{url}
    \usepackage[version=3]{mhchem}
    \usepackage{svg}
    \usepackage[raggedright]{sidecap}
    \usepackage[margin=1in]{geometry}


    \begin{document}

    \title{Statistically modelling the random nature of beta decay in Uranium-238}
    \author{Andrew Hamill 39047415}
    \date{\today}
    \maketitle

    \begin{abstract}
    \normalsize Radioactive sources decay randomly over time, with a fixed probability. The half life describes the time taken for a sample to halve its count rate. The count rates over a short period of time can be modelled by statistical distributions, most commonly Poisson, in order to model the spread of decays and calculate the respective standard deviation from this. The experimentally obtained values of standard deviation and count rate for the source, U-238, were used to test a Poisson fit and compare the two values of standard deviation. Here it was shown a count rate $ R = 1.08 \pm 0.06$ Bq and $\sigma_{hist} = 1.71$. Our Poisson parameter was $m = 1.80$. These two values of standard deviation are significantly close, suggesting a good fit to the experimental data, and thus it was concluded that beta decay of U-238 is random. This is reflective with the generally accepted model of radioactive decays, which appear random over single time intervals. From this it can be suggested random distributions such as Poisson can successfully model this decay over a set interval. 
    \end{abstract}

    \section{Introduction}
    % general background
    Unstable elements undergo radioactive decay over their lifetime in order to reach stability. This occurs through 3 main types of decay, alpha, beta and gamma, represented by their Greek alphabet symbols, $\alpha,\  \beta,\ \gamma$.  These describe emission of \ce{^{4}_{2}He}, \ce{^{0}_{-1}e}, and \ce{^{0}_{0}\gamma} respectively from the nucleus of the unstable element, with a sequential combination of these decays present until a stable state is reached. The decay of these elements can occur over a long period of time, and to measure and compare this we investigate an element's half life. This describes the time it takes for the count rate, $R$, of a substance to fall to half its initial value. This is unique to the element and its decay.
    % specific background 
    These decays are random within an arbitrary short time period as a result of the fixed probability of decay. Due to the long half lives, for example, the half life of \ce{^{238}_{}U} is $\cdots$ REF!! , they are hard to accurately measure.  It can be achieved from taking readings over several time periods, and solving the equations for exponential decay however the resolution of this method suffers in insufficiently long timer periods. Instead, the probability of decay can be modelled from several repeated smaller time periods. This can be modelled statistically to determine the  specific parameters of an element's decay. Statistical models such as Poisson are especially effective as they describe a discrete rate (here of decay) and have a flexible distribution that can be fit to a spread of data, making it the ideal to model the random nature of radioactive decay in a small time period. 
    
    % knowledge gap
    This experiment aimed to investigate the random nature of beta decay, specifically for elements with a substantial half life. Following this, the aim was to test how it can be modelled by a Poisson distribution and how the Poisson's parameters compared to the statistics of the raw experimental data. The difference between them, as well as the overall shape of the modelled distribution provide quantitative and qualitative analysis on the goodness of fit of the Poisson in this case. This is further extended with the inclusion of a Chi squared goodness of fit test, to determine whether the fit is statistically significant.  
    % here we show
    Here it was shown a count rate $ R = 1.08 \pm 0.06$ Bq and $\sigma_{hist} = 1.71$ 3 s.f. from our experimental data. Our Poisson parameter was $m = 1.80$ 3 s.f. Our Chi squared value was --, suggesting the model is an appropriate fit for our data. These standard deviations are close together suggesting the model is a good fit however ...
    %further development needed

    
    \section{background and Theory}
    % half life equation
    The concept of half life is only briefly discussed in this report, however it can be helpful to have a basic understanding of the concept. The half life relationship is defined as,
    \begin{equation}
        t_{\frac{1}{2}} = \frac{\ln{2}}{\lambda}
    \end{equation}
    Where $ t_{\frac{1}{2}}$ is the time for the number of particles to fall to half of it's original value (or the associated count rate), and $\lambda$ is the decay constant: the probability per decay. This relationship can be obtained from treating the decay as exponential, 
    $$N = N_0 e^{-\lambda t}$$
    for $N$ the number of particles and the $t$ time with $\lambda$ as above.  The $\lambda$ is the exponential coefficient of decay and thus is the probability of decay. 
    % chemical process of radioactive decay
   \\
   These elements are in a initial state of instability, and they decay to a more stable state. The nature of the instability and the structure of the atomic nuclei determines the type of the decay. For example, elements with a larger number of neutrons compared to protons generally decay via $\beta^{-}$ decay, hence a neutron will decay into a proton with the release of an electron and electron antineutrino. 
   There are many types of fundamental decays, Alpha $\alpha$, Beta plus/minus $\beta^{-}/\beta^{+}$, Gamma, $\gamma$, as well as electron capture and instantaneous fission (REFFF) to name the most understood ones. This report only concerns $\beta^{-}$ decay, defined by the following equation,
    $$ \ce{^{238}_{92}U} \longrightarrow \ce{^{234}_{90}Th} + \ce{^{4}_{2}\alpha} + \ce{^{0}_{0}\gamma}$$

    $$\ce{^{234}_{90}Th} \longrightarrow \ce{^{234}_{91}Pa} + \ce{^{0}_{-1}\beta^{-}} + \ce{^{0}_{0}\bar{\nu_{e}}} $$
   Where U is Uranium, Th is Thorium and Pa is Protactinium. Other particles release include the 3 decays mentioned above, as well as an electron antineutrino,$\ce{^{0}_{0}\bar{\nu_{e}}}$. Protactinium also further decays by $\beta$, however this equation is omitted here. This can also be analysed on a quark level, producing the follow quark equation:
 \newline
  $$ \ce{^{1}_{0}n} \longrightarrow \ce{^{1}_{1}p} + \ce{^{0}_{-1}e} + \ce{^{0}_{0}\bar{\nu_{e}}} $$
\newline
This describes the emission of an electron and how a neutron changes to a proton, taking an element with excess neutrons closer towards stability. This occurs through lots of decays over a large time period. 
   \\
% The decay we are studying is the $\beta^{-}$ decay of \ce{^{238}U}. This has an approximate half life of $4 x 10^9$ years REF. Why is this a beta emitter?
   \\
   In order to calculate the count rate, which is the rate at which the source decays per time interval (here seconds, $s$)  we define, 
   \begin{equation} R = \frac{N}{T}
   \end{equation}
   Where $R$ is the count rate, $T$ is the total time interval, $N$ is the total counts. This follows fairly intuitively from the definition. 
    % poisson
    The Poisson distribution will be used to model our data. The defining equation for the distribution is, 
    \begin{equation}
        P(N) = \frac{e^{-m}m^{n}}{N!}
    \end{equation}
    Where $P$ is the probability of obtaining $N$ counts, and $m$ is the mean. Notice the factorial in the definition, inciting that an integer input must be used throughout as the distribution is discrete. 
    As the Poisson is a random variable distribution, the mean, $m$ and standard deviation $\sigma_{Poisson}$ is defined by,
    \begin{equation}
        \sigma = \sqrt{m}
    \end{equation}
    We will use this to compare against the mean of the raw data according to the histogram. This is computed as the main of the whole data array. 
     \newline 
    \section{Experimental method}


   % \centering
   % \scalebox{0.5}
    \begin{figure}[ht]
        \begin{center}
            \def\svgwidth{\columnwidth}
            \includesvg[height=8.0cm]{final_diag.svg}
             \caption{“U-238 source placed with tweezers on blue holding tray, distance d from the Geiger-Müller tube which is connected to the shielded housing and electronic counter. This takes 100 * 3 s readings of counts from the $\beta$ decay of the source”}
             \label{fig:experimental setup}
        \end{center}
    \end{figure}

    Before taking readings of the radioactive source, the background count was first measured. To do this, the number of decayed nuclei were measured by a digital counter, connected up to a Geiger-Müller tube, in an interval of 100 seconds.
    % why 100s?
    
    From this, the background counts per second, or count rate in Becquerel (Bq) was calculated. This can be later considered when working out the average count rate in our data. 
    \newline
    In order to test the random fluctuations, the \ce{^{238}U} source was carefully placed at a distance from the Geiger-Müller tube such that the count rate would be $<$10 for any 3 second interval. In testing this was roughly 8cm. Due to the hypothesised nature of the counts in 3s, this doesn't need to be extensively measured as the probability for larger count rates falls quickly towards zero regardless of distance. Care should always be taken when handling radioactive sources. 
    \newline
    The count rate in 3s was then measured 100 times, ensuring the timer and counter was reset each measurement and the source was kept at uniform distance from the detector. This was achieved by placing the source on one of the adjustable shelves in the protective housing, which ensured the source was shielded when working with it for longer time intervals, as well as providing a stand for the Geiger-Müller tube. The data was collected raw and processed accordingly by computer software. 
    \newline 
    
    \section{Results and analysis/discussion}
    The data was plotted on a histogram (fig. 2) with integer bins, and error bars calculated based on the square root of the individual bin frequencies. This is due to the random error in decay measurements. 
    \newline
    To analyse the data, the software calculated mean of our data, $3.25$, and using equation (4), the histogram's standard deviation was calculated, $\sigma_{hist} = 1.8 (2.sf.)$. Following this, SciPy's Poisson and fit functions were used to fit a Poisson curve (based on eq.3) on top of the histogram. This gave a Poisson curve, mean ===, and by eq. 4, standard deviation, $\sigma_{Poisson}$ and the curve was then smoothed from Poisson's integer inputs. 
    It can be estimated qualitatively that the curve fits fairly well to the overall shape, however further investigation of the Poisson parameter compared to the histogram mean reveals, 
       \begin{figure}[]
        \begin{center}
            \def\svgwidth{\columnwidth}
            \includesvg[height=8.0cm]{histogram_new.svg}
             \caption{“Figure 2 illustrates the Poisson curve, fit ontop of the histogram with associated error bars. The Possion's parameter was calculated as, and $\sigma_{hist} = $”}
             \label{fig:experimental results 1}
        \end{center}
    \end{figure}
    \section{Conclusions}
    \section{References}
    \section{Appendices}
    Calculating $R$, $$ R = \frac{N}{T} \pm \frac{\sqrt{N}}{T}$$
    Where $R$ is the count rate, $T$ is the total time interval, $N$ is the total counts. With values $N =( 32.5 \pm 2) * 10^{1}$, $T= 3 * 100 [s]$, gives 
    $$R = 1.08 \pm 0.06$$ Bq
    \begin{table}[b]
        \centering
        \begin{tabular}{|c|c|}
        \hline
          \textbf{Count}  & \textbf{Frequency} \\
          \hline
           0  & 1 \\
           1 & 14\\
           2  & 25 \\
           3  & 18 \\
           4  & 20 \\
           5  & 11 \\
           6  & 6\\
           7  & 4 \\
           8  & 1 \\
           
           \hline
        \end{tabular}
        \caption{Binned data}
        \label{tab:my_label}
    \end{table}
    Poisson values 
    $N = 60$, and $x$ is the counts in 100s. 
    \begin{table}[]
        \centering
        \begin{tabular}{|c|c|c|c|}
         \hline
           counts (n)  & Poisson probability P(x=n) & $ f_{e}, P(x=n) * N$ & $f_{0}$ \\
            \hline
            0 & 0.0387742 & 3.87742 & 1 \\
            1 & 0.12601617 & 12.601617 & 14\\
            2 & 0.20477628 & 20.477628 & 25\\
            3 & 0.22184097 & 22.184097 & 18\\
            4 & 0.18024579 & 18.024579 & 20\\
            5 & 0.11715976 & 11.715976 & 11\\
            6 & 0.06346154 & 6.346154 & 6 \\
            7 & 0.02946428 & 2.946428 & 4\\
            8 & 0.01196986 & 1.1996986 & 1\\
             \hline

        \end{tabular}
        \caption{Raw Poisson data for GoF}
        \label{tab:my_label}
    \end{table}
    Following this, we combine frequencies less than 4 as they are too small for GoF. 
    \begin{table}[]
        \centering
        \begin{tabular}{|c|c|c|c|c|}
         \hline
           counts (n)  & Poisson probability P(x=n) & $ f_{e}, P(x=n) * N$ & $f_{0}$ & $\chi^{2}$ Contribution\\
 \hline
            <1 & 0.16479038 & 16.479038 & 15 &0.1327476401\\
            2 & 0.20477628 & 20.477628 & 25&0.9987410899\\
            3 & 0.22184097 & 22.184097 & 18&0.7891539469\\
            4 & 0.18024579 & 18.024579 & 20&0.2164981566\\
            5 & 0.11715976 & 11.715976 & 11&0.04375406988\\
            6 & 0.06346154 & 6.346154 & 6 &0.01888113521\\
            >7 & 0.04772526 & 4.772526 & 5 &0.01084214537\\      
 \hline
        \end{tabular}
        \caption{Corrected Frequencies and Poisson Contributions}
        \label{tab:my_label}
    \end{table}
    In order to calculate $\chi^{2}$, we firstly estimate the degrees of freedom, df. This dataset has 7 entries, and 1 estimated parameter, $m$ therefore, 
    $$df = 7 - 1 - 1 = 5$$
    We then use the equation for $\chi^{2}$, 
    $$\chi^{2} = \sum{\frac{(f_{O}-f_{e})^{2}}{f_{e}}}$$
    To generate a $\chi^{2} = 2.21061818$ and $p = 0.81930076$. Using the standard hypothesis,
    \newline
    $H_{0} =$ The Poisson is a good fit for the data
    \newline
    $H_{1} =$ The Poisson is not a good fit for the data
    \newline
    As our p value is >0.05, it is significant at the 
    5 percent level, deeming it a good fit for our data. 
     \end{document}